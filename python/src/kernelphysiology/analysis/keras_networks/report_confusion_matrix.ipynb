{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shutil\n",
    "import ntpath\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_names = [\n",
    "    'vgg16', 'vgg19',\n",
    "    'densenet121', 'densenet169', 'densenet201',\n",
    "    'mobilenet', 'mobilenet_v2',\n",
    "    'nasnetmobile', 'nasnetlarge',\n",
    "    'resnet50', 'inception_v3', 'inception_resnet_v2', 'xception',\n",
    "]\n",
    "\n",
    "experiments = ['KerasChromaticity', 'KerasRedGreen', 'KerasYellowBlue' , 'KerasLightness']\n",
    "\n",
    "num_samples = 50\n",
    "num_classes = 1000\n",
    "num_images = num_samples * num_classes\n",
    "gts = np.zeros((num_images, 1))\n",
    "for i in range(num_classes):\n",
    "    si = (i * num_samples)\n",
    "    ei = si + num_samples\n",
    "    gts[si:ei, 0] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusions(input_folder, output_folder, gts):\n",
    "    for experiment_input in glob.glob(input_folder + '/*/'):\n",
    "        experiment_name = experiment_input.split('/')[-2]\n",
    "        experiment_output = output_folder + '/' + experiment_name + '/'\n",
    "        if not os.path.exists(experiment_output):\n",
    "            os.mkdir(experiment_output)\n",
    "        # going through networks\n",
    "        for network_input in glob.glob(experiment_input + '/*/'):\n",
    "            network_name = network_input.split('/')[-2]\n",
    "            network_output = experiment_output + '/' + network_name + '/'\n",
    "            if not os.path.exists(network_output):\n",
    "                os.mkdir(network_output)\n",
    "            for file in glob.glob(network_input + '*.csv'):\n",
    "                experiment_predictions = np.loadtxt(file, delimiter=',')\n",
    "                current_matrix = confusion_matrix(gts, experiment_predictions[:, 2])\n",
    "                parameter_name = file.split('/')[-1]\n",
    "                out_file = network_output + '/' + parameter_name\n",
    "                print(out_file)\n",
    "                np.savetxt(out_file, current_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_network(input_folder, output_folder, network_name, experiments):\n",
    "    file = input_folder + '/KerasOriginal/' + network_name + '/' + network_name + '_original.csv'\n",
    "    original_predictions = np.loadtxt(file, delimiter=',')\n",
    "\n",
    "    confusion_matrices = []\n",
    "    for experiment in experiments:\n",
    "        files = glob.glob('%s/%s/%s/*.csv' % (input_folder, experiment, network_name))\n",
    "        output_folder = '%s/%s/' % (output_folder, experiment)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.mkdir(output_folder)\n",
    "        output_folder = '%s/%s/' % (output_folder, network_name)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.mkdir(output_folder)\n",
    "        for file in files:\n",
    "            if '_0.0.csv' in file:\n",
    "                experiment_predictions = np.loadtxt(file, delimiter=',')\n",
    "                accuracy_drop = np.zeros((1000, 1))\n",
    "                for i in range(1000):\n",
    "                    accuracy_drop[i, 0] = experiment_predictions[i, i] / original_predictions[i, i]\n",
    "                confusion_matrices.append(accuracy_drop)\n",
    "                out_file = output_folder + 'accuracy_drop.csv'\n",
    "                np.savetxt(out_file, accuracy_drop, delimiter=',')\n",
    "    return confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/arash/Desktop/ICCV_Results/KerasConfusions/'\n",
    "output_folder = '/home/arash/Desktop/ICCV_Results/KerasResults/'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# generate_confusions(input_folder, output_folder, gts)\n",
    "\n",
    "network_results = np.zeros((1000, 13))\n",
    "for i, network_name in enumerate(network_names):\n",
    "    experiments_results = do_one_network(input_folder, output_folder, network_name, experiments[2:3])\n",
    "    network_results[:, i:i+1] = experiments_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_corss = np.ones((13, 13))\n",
    "suffix = '_red_green_0.0.csv'\n",
    "folder = 'KerasRedGreen/'\n",
    "for i in range(net_corss.shape[0] - 1):\n",
    "    file_i = input_folder + folder + network_names[i] + '/' + network_names[i] + suffix\n",
    "    org_result_i = np.loadtxt(file_i, delimiter=',')\n",
    "    for j in range(i + 1, net_corss.shape[0]):\n",
    "        file_j = input_folder + folder + network_names[j] + '/' + network_names[j] + suffix\n",
    "        org_result_j = np.loadtxt(file_j, delimiter=',')\n",
    "#         corr, p_value = pearsonr(network_results[:, i], network_results[:, j])\n",
    "        corr, p_value = pearsonr(org_result_i.flatten(), org_result_j.flatten())\n",
    "        net_corss[i, j] = corr\n",
    "        net_corss[j, i] = corr\n",
    "report_file = '/home/arash/Desktop/ICCV_Results/KerasReports/'\n",
    "np.savetxt(report_file + 'red_green_confusion_corr.csv', net_corss,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['barn spider']\n"
     ]
    }
   ],
   "source": [
    "indices = np.where((network_results > 1).sum(axis=1) > 12)\n",
    "print(len(imagenet_labels[indices]))\n",
    "print(imagenet_labels[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brambling', 'goldfinch', 'house finch', 'junco'], dtype='<U32')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_labels[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "label_file = '/home/arash/Desktop/ILSVRC2012_validation_labels.json'\n",
    "with open(label_file) as f:\n",
    "    imagenet_labels = json.load(f)\n",
    "imagenet_labels = np.array(imagenet_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
